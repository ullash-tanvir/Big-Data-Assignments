{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0eb47fc",
      "metadata": {
        "id": "a0eb47fc"
      },
      "source": [
        "### Introduction to PyArrow\n",
        "\n",
        "*   PyArrow serves as a cross-language development environment specifically designed for in-memory data.\n",
        "*   Its primary goal is to boost the performance of analytics applications.\n",
        "*   Emerging from the Apache Arrow project, PyArrow aims to make data interoperability better across different languages and systems.\n",
        "*   It uses an in-memory columnar data representation, offering an optimized memory footprint for complex data structures.\n",
        "*   With zero-copy reads, it facilitates quick data sharing between Python and other languages, sidestepping the need for serialization.\n",
        "*   It supports schemas and metadata, providing data structures that are rich and self-describing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3013192",
      "metadata": {
        "id": "b3013192"
      },
      "source": [
        "### PyArrow and Parquet\n",
        "\n",
        "*   PyArrow offers seamless reading and writing operations for Parquet files.\n",
        "*   With column pruning, you can selectively read only the necessary columns from a Parquet file, reducing I/O time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9cd6488d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "9cd6488d",
        "outputId": "129dc2b1-5e8b-498a-f1c6-324f9e66d699"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-21c33ed6767d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_file.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'column2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Potentially conver the file to pandas if needed for more sophisticated splicing and dicing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2778\u001b[0m             )\n\u001b[1;32m   2779\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2780\u001b[0;31m             dataset = _ParquetDatasetV2(\n\u001b[0m\u001b[1;32m   2781\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m                 \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2377\u001b[0m                 infer_dictionary=True)\n\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m         self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   2380\u001b[0m                                    \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_multiple_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_single_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     options = FileSystemFactoryOptions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_ensure_single_source\u001b[0;34m(path, filesystem)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: your_file.parquet"
          ]
        }
      ],
      "source": [
        "import pyarrow.parquet as pq\n",
        "table = pq.read_table('your_file.parquet', columns=['column1', 'column2'])\n",
        "# Potentially conver the file to pandas if needed for more sophisticated splicing and dicing.\n",
        "df = table.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b46b332",
      "metadata": {
        "id": "8b46b332"
      },
      "source": [
        "### Apache Arrow\n",
        "\n",
        "```The core feature of Apache Arrow is its in-memory columnar format. This language-agnostic standard is designed to store structured, table-like datasets efficiently in memory. The data format supports a rich set of data types, including nested and user-defined types, making it suitable for analytic databases, data frame libraries, and more.```\n",
        "\n",
        "The Apache Arrow Project\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebcdbec",
      "metadata": {
        "id": "3ebcdbec"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://blog.djnavarro.net/posts/2021-11-19_starting-apache-arrow-in-r/img/with_arrow.jpg\" width=700>\n",
        "</div>\n",
        "\n",
        "[picture source](https://blog.djnavarro.net/posts/2021-11-19_starting-apache-arrow-in-r/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2da3f1db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2da3f1db",
        "outputId": "2564508b-8c80-4538-d45a-ff2310e60559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: unexpected EOF while looking for matching ``'\n",
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarrow`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cac5bc2",
      "metadata": {
        "id": "4cac5bc2"
      },
      "source": [
        "### PyArrow Data Structures\n",
        "\n",
        "*   PyArrow offers a suite of low-level data structures and methods optimized for both speed and flexibility.\n",
        "*   These structures can be used seamlessly across multiple languages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57327800",
      "metadata": {
        "id": "57327800"
      },
      "source": [
        "### Arrow Array\n",
        "\n",
        "*   An Arrow Array is essentially a column of data stored in an efficient, contiguous block of memory.\n",
        "*   Unlike Python lists, these arrays are optimized for high-speed operations and can be transferred across languages without incurring serialization costs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "22df9c61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22df9c61",
        "outputId": "32ab3bc4-2b59-4e18-d549-487662746726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyarrow.lib.Int64Array'>\n",
            "---------\n",
            "[\n",
            "  1,\n",
            "  2,\n",
            "  3,\n",
            "  4,\n",
            "  5\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import pyarrow as pa\n",
        "arrow_array = pa.array([1, 2, 3, 4, 5])\n",
        "print(type(arrow_array))\n",
        "print(\"---------\")\n",
        "print(arrow_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4bcda45",
      "metadata": {
        "id": "e4bcda45"
      },
      "source": [
        "### Arrow Buffer\n",
        "\n",
        "* While not a data structure per se, Arrow Buffers are pivotal in understanding Arrow functionality.\n",
        "* Buffers are blocks of memory that house the data for Arrow Arrays, contributing to efficient storage.\n",
        "* You can even access the buffer's content directly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "35754c14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35754c14",
        "outputId": "1fcec87a-d6e2-4067-839a-97ddb5797231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyarrow.lib.Buffer object at 0x7faa600e28b0>\n"
          ]
        }
      ],
      "source": [
        "buffer = arrow_array.buffers()[1]\n",
        "print(buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "95c81af6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95c81af6",
        "outputId": "e4455099-36b9-425e-8244-f594d6bfaa7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
          ]
        }
      ],
      "source": [
        "byte_data = buffer.to_pybytes()\n",
        "print(byte_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efed66a0",
      "metadata": {
        "id": "efed66a0"
      },
      "source": [
        "### Arrow Buffer - Cont'd\n",
        "\n",
        "* Here, the buffer's data contains 40 bytes, each 8 bytes representing an `int64` value for each of the 5 elements in the array.\n",
        "* You can use this buffer data to create a new NumPy array, showing that Arrow and NumPy can share memory.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "4d462d9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d462d9a",
        "outputId": "17db7156-2c7e-4d86-abff-1bd54efe3633"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import numpy as np\n",
        "numpy_array = np.frombuffer(buffer, dtype=np.int64)\n",
        "numpy_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "983cb2a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "983cb2a0",
        "outputId": "e362ec54-c6c8-4cb8-ddd2-fc9fe67132d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "np.shares_memory(arrow_array, numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac880c9",
      "metadata": {
        "id": "3ac880c9"
      },
      "source": [
        "### Arrow Buffer - Cont'd\n",
        "\n",
        "* Both `arrow_array` and `numpy_array` share the same underlying data, demonstrating the concept of zero-copy.\n",
        "* You can confirm this by modifying a value in one array and seeing the change in the other.\n",
        "  * Both arrays will now show the updated value.\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7d6df885",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d6df885",
        "outputId": "fb9ecece-fd9e-4152-ea9f-d806b58db338"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "numpy_array[1] = 0\n",
        "numpy_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "78887976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78887976",
        "outputId": "63df1f3d-bc81-4f78-da16-56d3cd057c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.Int64Array object at 0x7faa609f2da0>\n",
              "[\n",
              "  1,\n",
              "  0,\n",
              "  3,\n",
              "  4,\n",
              "  5\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "arrow_array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b45749",
      "metadata": {
        "id": "92b45749"
      },
      "source": [
        "### Schema\n",
        "\n",
        "* A schema in PyArrow defines the structure, column names, and types for Arrow Arrays.\n",
        "* Schemas are crucial as they set the framework for data manipulation and operations in Arrow.\n",
        "  * Give Arrow an idea on how to encode the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "186b4447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186b4447",
        "outputId": "1a8f274e-24c0-49d8-fde4-6b5f9e5290a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "column1: int64\n",
            "column2: string\n"
          ]
        }
      ],
      "source": [
        "schema = pa.schema([('column1', pa.int64()), ('column2', pa.string())])\n",
        "print(schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd46394",
      "metadata": {
        "id": "4bd46394"
      },
      "source": [
        "### Chunked Array\n",
        "\n",
        "*   A Chunked Array in PyArrow is like a single Arrow Array but divided into smaller \"chunks.\"\n",
        "*   This structure allows for the storage and processing of datasets that are too large to fit in memory.\n",
        "*   It's commonly used in distributed computing frameworks and data streaming scenarios.\n",
        "\n",
        "* For example:\n",
        "  * you could have data sent in chunks to optimize throughput\n",
        "  * you might have multiple nodes in a distributed system each producing Arrow Arrays that are collected and represented as a ChunkedArray by the master node.\n",
        "\n",
        "* From a user perspective, a Chunked Array appears as a contiguous sequence of data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e4c3087a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4c3087a",
        "outputId": "467a6ac6-4f6d-4d4a-8317-6bbbac20ef42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.ChunkedArray object at 0x7faa600c3880>\n",
              "[\n",
              "  [\n",
              "    0,\n",
              "    1,\n",
              "    2,\n",
              "    3,\n",
              "    4\n",
              "  ],\n",
              "  [\n",
              "    5,\n",
              "    6,\n",
              "    7,\n",
              "    8,\n",
              "    9,\n",
              "    10\n",
              "  ]\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "results_node_1 = pa.array([0,1,2,3,4])\n",
        "results_node_2 = pa.array([5,6,7,8,9,10])\n",
        "chunked_array = pa.chunked_array([results_node_1, results_node_2])\n",
        "chunked_array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be520fe2",
      "metadata": {
        "id": "be520fe2"
      },
      "source": [
        "### Chunked Array - Cont'd\n",
        "\n",
        "* You can index into a single position or even across multiple chunks, making the data handling more versatile.\n",
        "* You can also access individual chunks, allowing for parallel processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "87d579f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87d579f7",
        "outputId": "7e3479be-7824-4e8b-cfe5-ff08db91e785"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.ChunkedArray object at 0x7faa600cf420>\n",
              "[\n",
              "  [\n",
              "    3,\n",
              "    4\n",
              "  ],\n",
              "  [\n",
              "    5\n",
              "  ]\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "chunked_array[3:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "356cedc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "356cedc3",
        "outputId": "656c7fb8-a728-4d06-dd0f-2a71bedd5e35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.Int64Array object at 0x7faa600b4ac0>\n",
              "[\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "chunked_array.chunk(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f948c663",
      "metadata": {
        "id": "f948c663"
      },
      "source": [
        "### Table\n",
        "\n",
        "* A Table in PyArrow is a container for multiple Arrow ChunkedArrays with a common schema.\n",
        "* Each column in the Table is an Arrow ChunkedArray, and all columns share the same length.\n",
        "* Tables offer an ideal format for handling data in the form of a dataframe.\n",
        "* Tables can also be partitioned across multiple files for large-scale storage, or to be sent across a network, or even to be stored in-memory on a single machine.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "98dc32df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98dc32df",
        "outputId": "cbc8fee6-1ff1-4458-e398-d2a93e46bd91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "column1: int64\n",
              "column2: string\n",
              "----\n",
              "column1: [[0,1,2,3,4]]\n",
              "column2: [[\"a\",\"b\",\"c\",\"d\",\"e\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "column1 = pa.array([0, 1, 2, 3, 4])\n",
        "column2 = pa.array(['a', 'b', 'c', 'd', 'e'])\n",
        "table = pa.table({'column1': column1, 'column2': column2})\n",
        "\n",
        "table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cdaa066",
      "metadata": {
        "id": "9cdaa066"
      },
      "source": [
        "### Record Batch\n",
        "\n",
        "*   A Record Batch is a collection of Arrow Arrays (columns) with the same length, all of which are bundled together with a schema.\n",
        "*   Much like a Chunked Array is a collection of Arrow Arrays, a Table in Apache Arrow is a collection of Record Batches.\n",
        "\n",
        "* Conceptual Relationship\n",
        "  *   In Apache Arrow, the concept of a Record Batch is to a Table what an Arrow Array is to a Chunked Array.\n",
        "    *   Arrays can be grouped together to form a Chunked Array.\n",
        "    *   Record Batches can be grouped together to form a Table.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ec7454b",
      "metadata": {
        "id": "0ec7454b"
      },
      "source": [
        "### Record Batch - Cont'd\n",
        "\n",
        "* Use Cases\n",
        "  *   The choice between using a Record Batch or a Table often depends on your specific needs. E.g.:\n",
        "    \n",
        "  *  Streaming Data: If you need to process data on-the-fly, perhaps in a streaming application where you want to process each chunk as it arrives, Record Batches are a good choice.\n",
        "    *   You can serialize and process each Record Batch independently as they arrive, without having to wait for the entire data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5606ad83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5606ad83",
        "outputId": "06347a86-dd89-4af9-8b41-e011f456fdd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.RecordBatch\n",
              "column1: int64\n",
              "column2: string"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "\n",
        "column1_array = pa.array([1, 2, 3, 4, 5])\n",
        "column2_array = pa.array(['a', 'b', 'c', 'd', 'e'])\n",
        "schema = pa.schema([('column1', pa.int64()), ('column2', pa.string())])\n",
        "\n",
        "record_batch = pa.record_batch([column1_array, column2_array], schema=schema)\n",
        "record_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "18702115",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18702115",
        "outputId": "7dc5c767-239c-416f-c20c-b9c5a16c2478"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<pyarrow.lib.Int64Array object at 0x7faa60093be0>\n",
              " [\n",
              "   1,\n",
              "   2,\n",
              "   3,\n",
              "   4,\n",
              "   5\n",
              " ],\n",
              " <pyarrow.lib.StringArray object at 0x7faa60093b20>\n",
              " [\n",
              "   \"a\",\n",
              "   \"b\",\n",
              "   \"c\",\n",
              "   \"d\",\n",
              "   \"e\"\n",
              " ]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "record_batch.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "48fe3e61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48fe3e61",
        "outputId": "703d4c19-e7d2-4427-8950-a628d5cc1cc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.Int64Array object at 0x7faa600b7ac0>\n",
              "[\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "record_batch[\"column1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "359f94f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "359f94f8",
        "outputId": "ba8ca39c-adec-4214-c9d3-a5aef434830e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "column1: int64\n",
              "column2: string\n",
              "----\n",
              "column1: [[1,2,3,4,5],[6,7,8,9,10]]\n",
              "column2: [[\"a\",\"b\",\"c\",\"d\",\"e\"],[\"f\",\"g\",\"h\",\"i\",\"j\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "\n",
        "column1_array_new = pa.array([6, 7, 8, 9, 10])\n",
        "column2_array_new = pa.array(['f', 'g', 'h', 'i', 'j'])\n",
        "record_batch_new = pa.record_batch([column1_array_new, column2_array_new], schema=schema)\n",
        "\n",
        "\n",
        "table = pa.Table.from_batches([record_batch, record_batch_new], schema=schema)\n",
        "table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaf06e41",
      "metadata": {
        "id": "aaf06e41"
      },
      "source": [
        "### Record Batch - Cont'd\n",
        "\n",
        "* In the example above, two Record Batches are combined to create a single Table.\n",
        "  * This is analogous to how individual Arrow Arrays can be combined to create a Chunked Array\n",
        "  * Reinforces the idea that a Record Batch is to a Table what an Arrow Array is to a Chunked Array.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ede8f6b",
      "metadata": {
        "id": "1ede8f6b"
      },
      "source": [
        "### Dive Into Real Data: Parquet and Memory Efficiency\n",
        "\n",
        "1.  Let's get hands-on and read a Parquet file using Apache Arrow.\n",
        "2.  Take note: the size of the data when using PyArrow is substantially smaller than a Pandas DataFrame for the same data.\n",
        "3.  Think of this as a little teaser to whet your appetite for data science goodness.\n",
        "\n",
        "**Note**: Here, I'm using the `parquet` module from the PyArrow package. This module knows how to read Parquet files among other things.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "adaeb94f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "adaeb94f",
        "outputId": "758ba7a6-c14f-4334-b797-804cfb5c91d2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-4ae7f89f323d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2778\u001b[0m             )\n\u001b[1;32m   2779\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2780\u001b[0;31m             dataset = _ParquetDatasetV2(\n\u001b[0m\u001b[1;32m   2781\u001b[0m                 \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m                 \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2377\u001b[0m                 infer_dictionary=True)\n\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m         self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   2380\u001b[0m                                    \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_multiple_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_single_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     options = FileSystemFactoryOptions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_ensure_single_source\u001b[0;34m(path, filesystem)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mpaths_or_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet"
          ]
        }
      ],
      "source": [
        "import pyarrow.parquet as pq\n",
        "table = pq.read_table('/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet')\n",
        "table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "95e46add",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95e46add",
        "outputId": "06b5c525-43c5-4fb9-e157-c67444569426"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.73225998878479e-07"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import sys\n",
        "sys.getsizeof(table) / 1024 / 1024 / 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "cc4504cd",
      "metadata": {
        "id": "cc4504cd"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import psutil\n",
        "# def print_mem():\n",
        "#     gig = psutil.Process(os.getpid()).memory_info().rss / 1024 ** 3\n",
        "#     print(f\"{gig} gigabytes\")\n",
        "\n",
        "# print_mem()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4b0e7e66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "4b0e7e66",
        "outputId": "933b8be1-ed87-4e6e-bf6c-0ad089cbb2a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0ef7315f154c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet('/Users/mahdi/Downloads/fhvhv_tripdata_2022-06.parquet')\n",
        "sys.getsizeof(df) / 1024 / 1024 / 1024\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f4201f",
      "metadata": {
        "id": "31f4201f"
      },
      "source": [
        "\n",
        "### Apache Arrow Datasets\n",
        "\n",
        "\n",
        "*   Datasets in PyArrow let you work with large tabular data, even when it's larger than your machine's memory\n",
        "*   It offers lazy data access, meaning you don't have to load the entire dataset into memory.\n",
        "*   Datasets support data discovery, partitioning, and compatibility with various file systems like AWS, Google Cloud, and local storage.\n",
        "  * I can read from AWS or Google without having to install anything.\n",
        "\n",
        "* import the dataset library as:\n",
        "\n",
        "```python\n",
        "import pyarrow.dataset as ds\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb50e765",
      "metadata": {
        "id": "bb50e765"
      },
      "source": [
        "### Dataset Overview\n",
        "\n",
        "* Provider: New York City Taxi and Limousine Commission (TLC)\n",
        "* Data hosted on AWS. The URSA-LAB company account.\n",
        "* Contains data on millions of taxi and limousine trips in NYC\n",
        "* Time Period: 2009 to 2019\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "00b42c08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00b42c08",
        "outputId": "f00a618b-360c-4844-ba85-be02df8454ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: aws: command not found\n"
          ]
        }
      ],
      "source": [
        "# **Note**: In the AWS S3 listing, \"PRE\" stands for \"prefix,\" essentially representing a folder or directory.\n",
        "\n",
        "!aws s3 ls \"s3://ursa-labs-taxi-data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "f4c3ab1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4c3ab1e",
        "outputId": "44d98cee-e7fb-4c5b-f1ca-03808d1a61b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: aws: command not found\n"
          ]
        }
      ],
      "source": [
        "!aws s3 ls \"s3://ursa-labs-taxi-data/2009/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b3da9fb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3da9fb0",
        "outputId": "7eb60bdf-1983-4536-9ebb-adc76c3be626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 158 ms, sys: 38.7 ms, total: 196 ms\n",
            "Wall time: 2.34 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow._dataset.FileSystemDataset at 0x7faa600c9530>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "%%time\n",
        "import pyarrow.dataset as ds\n",
        "dataset = ds.dataset(\"s3://ursa-labs-taxi-data/\", partitioning=[\"year\", \"month\"])\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f60be24b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f60be24b",
        "outputId": "29622809-e38f-41a2-a3fc-0aa580ead635"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(dataset.files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "bdea9bad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdea9bad",
        "outputId": "ed4ae7e0-b204-491b-902a-6b4d2d353ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ursa-labs-taxi-data/2009/01/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/02/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/03/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/04/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/05/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/06/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/07/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/08/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/09/data.parquet',\n",
              " 'ursa-labs-taxi-data/2009/10/data.parquet']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "dataset.files[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "07d2e4ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07d2e4ce",
        "outputId": "483116e9-1448-4fda-e813-21dfae877050"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.compute.Expression ((year == 2009) and (month == 1))>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Here's how to load just one file (a fragment) and its schema:\n",
        "\n",
        "frag = next(dataset.get_fragments())\n",
        "frag.partition_expression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d98407",
      "metadata": {
        "id": "36d98407"
      },
      "source": [
        "#### Play with a Single File\n",
        "\n",
        "* Let's read in the data from this single fragment\n",
        "* Take a look at the data\n",
        "* List of column names\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "fd4124c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd4124c3",
        "outputId": "bb20d5b5-9e2c-4ee1-8c83-7a0a1f4added"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.83 s, sys: 2.53 s, total: 9.37 s\n",
            "Wall time: 2min 57s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "vendor_id: string\n",
              "pickup_at: timestamp[us]\n",
              "dropoff_at: timestamp[us]\n",
              "passenger_count: int8\n",
              "trip_distance: float\n",
              "pickup_longitude: float\n",
              "pickup_latitude: float\n",
              "rate_code_id: null\n",
              "store_and_fwd_flag: string\n",
              "dropoff_longitude: float\n",
              "dropoff_latitude: float\n",
              "payment_type: string\n",
              "fare_amount: float\n",
              "extra: float\n",
              "mta_tax: float\n",
              "tip_amount: float\n",
              "tolls_amount: float\n",
              "total_amount: float\n",
              "----\n",
              "vendor_id: [[\"VTS\",\"VTS\",\"VTS\",\"DDS\",\"DDS\",...,\"DDS\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],[\"CMT\",\"DDS\",\"DDS\",\"CMT\",\"DDS\",...,\"CMT\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],...,[\"CMT\",\"CMT\",\"DDS\",\"CMT\",\"CMT\",...,\"VTS\",\"CMT\",\"VTS\",\"VTS\",\"VTS\"],[\"VTS\",\"VTS\",\"VTS\",\"VTS\",\"VTS\",...,\"VTS\",\"VTS\",\"CMT\",\"VTS\",\"CMT\"]]\n",
              "pickup_at: [[2009-01-04 02:52:00.000000,2009-01-04 03:31:00.000000,2009-01-03 15:43:00.000000,2009-01-01 20:52:58.000000,2009-01-24 16:18:23.000000,...,2009-01-01 22:42:49.000000,2009-01-04 18:27:32.000000,2009-01-04 11:48:33.000000,2009-01-04 23:21:04.000000,2009-01-04 16:11:27.000000],[2009-01-04 21:54:44.000000,2009-01-02 15:41:33.000000,2009-01-02 13:20:36.000000,2009-01-04 14:00:03.000000,2009-01-28 13:53:51.000000,...,2009-01-25 10:50:39.000000,2009-01-25 11:49:11.000000,2009-01-21 12:47:20.000000,2009-01-25 13:20:23.000000,2009-01-30 12:53:03.000000],...,[2009-01-21 08:17:06.000000,2009-01-20 20:09:15.000000,2009-01-09 19:14:11.000000,2009-01-20 21:02:47.000000,2009-01-21 08:37:05.000000,...,2009-01-25 00:04:00.000000,2009-01-01 01:30:02.000000,2009-01-25 14:40:00.000000,2009-01-22 20:46:00.000000,2009-01-25 13:07:00.000000],[2009-01-25 06:39:00.000000,2009-01-25 15:00:00.000000,2009-01-25 10:11:00.000000,2009-01-25 04:19:00.000000,2009-01-23 19:59:00.000000,...,2009-01-27 14:36:00.000000,2009-01-27 13:56:00.000000,2009-01-23 08:39:44.000000,2009-01-24 23:05:00.000000,2009-01-23 14:39:02.000000]]\n",
              "dropoff_at: [[2009-01-04 03:02:00.000000,2009-01-04 03:38:00.000000,2009-01-03 15:57:00.000000,2009-01-01 21:14:00.000000,2009-01-24 16:24:56.000000,...,2009-01-01 23:01:49.000000,2009-01-04 18:31:39.000000,2009-01-04 11:54:40.000000,2009-01-04 23:24:16.000000,2009-01-04 16:24:19.000000],[2009-01-04 21:58:25.000000,2009-01-02 15:45:22.000000,2009-01-02 13:32:59.000000,2009-01-04 14:03:02.000000,2009-01-28 14:02:28.000000,...,2009-01-25 10:52:42.000000,2009-01-25 12:07:32.000000,2009-01-21 13:01:08.000000,2009-01-25 13:24:09.000000,2009-01-30 12:59:29.000000],...,[2009-01-21 09:16:34.000000,2009-01-20 20:12:52.000000,2009-01-09 19:27:18.000000,2009-01-20 21:18:31.000000,2009-01-21 08:40:51.000000,...,2009-01-25 00:23:00.000000,2009-01-01 01:49:06.000000,2009-01-25 14:48:00.000000,2009-01-22 20:53:00.000000,2009-01-25 13:20:00.000000],[2009-01-25 06:44:00.000000,2009-01-25 15:04:00.000000,2009-01-25 10:16:00.000000,2009-01-25 04:33:00.000000,2009-01-23 20:14:00.000000,...,2009-01-27 14:46:00.000000,2009-01-27 14:02:00.000000,2009-01-23 09:02:15.000000,2009-01-24 23:15:00.000000,2009-01-23 15:35:15.000000]]\n",
              "passenger_count: [[1,3,5,1,1,...,1,1,1,1,2],[2,2,2,1,2,...,2,2,1,1,1],...,[1,1,1,1,1,...,5,2,5,1,5],[5,1,1,5,1,...,5,1,1,3,1]]\n",
              "trip_distance: [[2.63,4.55,10.35,5,0.4,...,3.7,0.9,0.5,1.1,1.3],[1.1,0.6,0.9,1.2,1,...,1,6.8,1.3,0.7,1],...,[20.7,0.2,2.1,2.3,0.5,...,5.2,4.3,0.86,1.62,1.53],[1.43,0.58,1.36,3.02,2.91,...,0.89,1.94,3.8,3.85,17.3]]\n",
              "pickup_longitude: [[-73.99196,-73.9821,-74.00259,-73.974266,-74.00158,...,-73.992744,-73.99128,-73.98005,-73.97288,-73.9776],[-73.9908,-73.975716,-73.97441,-73.97065,-73.990135,...,-73.97786,-73.95457,0,-73.97422,-73.966644],...,[-73.78204,-73.98393,-73.979645,-73.99633,-73.98092,...,-73.97414,-73.982925,-73.953926,-73.999596,-73.99288],[-73.970604,-73.99453,-73.9917,-74.00047,-73.99772,...,-73.98201,-73.972786,-73.97747,-73.98129,0]]\n",
              "pickup_latitude: [[40.721565,40.73629,40.739746,40.790955,40.719383,...,40.713802,40.723892,40.754658,40.79333,40.752],[40.751076,40.748226,40.76322,40.752747,40.740852,...,40.74217,40.78086,0,40.783566,40.804012],...,[40.644768,40.749287,40.7554,40.737335,40.76395,...,40.78377,40.73503,40.76648,40.733482,40.72419],[40.76505,40.75172,40.739643,40.728706,40.72436,...,40.74333,40.76199,40.75186,40.753,0]]\n",
              "rate_code_id: [65536 nulls,65536 nulls,...,65536 nulls,2173 nulls]\n",
              "store_and_fwd_flag: [[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null],...,[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null]]\n",
              "dropoff_longitude: [[-73.993805,-73.95585,-73.86998,-73.99656,-74.00838,...,-73.98663,-73.98523,-73.98596,-73.981995,-73.99347],[-74.00014,-73.97249,-73.98696,-73.98271,-73.99506,...,-73.98757,-73.93975,0,-73.982,-73.95343],...,[-73.96209,-73.98791,-74.005585,-73.97921,-73.98632,...,-73.917816,-73.96772,-73.96618,-74.00464,-74.00712],[-73.980606,-74.00163,-73.97803,-73.97005,-73.98376,...,-73.99433,-73.95148,-74.00991,-73.949455,0]]\n",
              "..."
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "%%time\n",
        "frag_table = frag.to_table()\n",
        "frag_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f1ed59a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1ed59a4",
        "outputId": "9d923e2b-26f7-4f24-aa77-f2ccfe53adf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vendor_id',\n",
              " 'pickup_at',\n",
              " 'dropoff_at',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'pickup_longitude',\n",
              " 'pickup_latitude',\n",
              " 'rate_code_id',\n",
              " 'store_and_fwd_flag',\n",
              " 'dropoff_longitude',\n",
              " 'dropoff_latitude',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'total_amount']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "frag_table.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "53c8e2bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53c8e2bb",
        "outputId": "1d480d2e-43d0-4cff-b07c-14e6a8221203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14092413"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "frag_table.num_rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "a546d3fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a546d3fc",
        "outputId": "21965e7c-eeee-4cbd-be2d-1e15ec0bdd18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "vendor_id: string\n",
              "pickup_at: timestamp[us]\n",
              "dropoff_at: timestamp[us]\n",
              "passenger_count: int8\n",
              "trip_distance: float\n",
              "pickup_longitude: float\n",
              "pickup_latitude: float\n",
              "rate_code_id: null\n",
              "store_and_fwd_flag: string\n",
              "dropoff_longitude: float\n",
              "dropoff_latitude: float\n",
              "payment_type: string\n",
              "fare_amount: float\n",
              "extra: float\n",
              "mta_tax: float\n",
              "tip_amount: float\n",
              "tolls_amount: float\n",
              "total_amount: float\n",
              "----\n",
              "vendor_id: [[\"VTS\",\"VTS\",\"VTS\",\"DDS\",\"DDS\",...,\"DDS\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],[\"CMT\",\"DDS\",\"DDS\",\"CMT\",\"DDS\",...,\"CMT\",\"CMT\",\"CMT\",\"CMT\",\"CMT\"],...,[\"CMT\",\"CMT\",\"DDS\",\"CMT\",\"CMT\",...,\"VTS\",\"CMT\",\"VTS\",\"VTS\",\"VTS\"],[\"VTS\",\"VTS\",\"VTS\",\"VTS\",\"VTS\",...,\"VTS\",\"VTS\",\"CMT\",\"VTS\",\"CMT\"]]\n",
              "pickup_at: [[2009-01-04 02:52:00.000000,2009-01-04 03:31:00.000000,2009-01-03 15:43:00.000000,2009-01-01 20:52:58.000000,2009-01-24 16:18:23.000000,...,2009-01-01 22:42:49.000000,2009-01-04 18:27:32.000000,2009-01-04 11:48:33.000000,2009-01-04 23:21:04.000000,2009-01-04 16:11:27.000000],[2009-01-04 21:54:44.000000,2009-01-02 15:41:33.000000,2009-01-02 13:20:36.000000,2009-01-04 14:00:03.000000,2009-01-28 13:53:51.000000,...,2009-01-25 10:50:39.000000,2009-01-25 11:49:11.000000,2009-01-21 12:47:20.000000,2009-01-25 13:20:23.000000,2009-01-30 12:53:03.000000],...,[2009-01-21 08:17:06.000000,2009-01-20 20:09:15.000000,2009-01-09 19:14:11.000000,2009-01-20 21:02:47.000000,2009-01-21 08:37:05.000000,...,2009-01-25 00:04:00.000000,2009-01-01 01:30:02.000000,2009-01-25 14:40:00.000000,2009-01-22 20:46:00.000000,2009-01-25 13:07:00.000000],[2009-01-25 06:39:00.000000,2009-01-25 15:00:00.000000,2009-01-25 10:11:00.000000,2009-01-25 04:19:00.000000,2009-01-23 19:59:00.000000,...,2009-01-27 14:36:00.000000,2009-01-27 13:56:00.000000,2009-01-23 08:39:44.000000,2009-01-24 23:05:00.000000,2009-01-23 14:39:02.000000]]\n",
              "dropoff_at: [[2009-01-04 03:02:00.000000,2009-01-04 03:38:00.000000,2009-01-03 15:57:00.000000,2009-01-01 21:14:00.000000,2009-01-24 16:24:56.000000,...,2009-01-01 23:01:49.000000,2009-01-04 18:31:39.000000,2009-01-04 11:54:40.000000,2009-01-04 23:24:16.000000,2009-01-04 16:24:19.000000],[2009-01-04 21:58:25.000000,2009-01-02 15:45:22.000000,2009-01-02 13:32:59.000000,2009-01-04 14:03:02.000000,2009-01-28 14:02:28.000000,...,2009-01-25 10:52:42.000000,2009-01-25 12:07:32.000000,2009-01-21 13:01:08.000000,2009-01-25 13:24:09.000000,2009-01-30 12:59:29.000000],...,[2009-01-21 09:16:34.000000,2009-01-20 20:12:52.000000,2009-01-09 19:27:18.000000,2009-01-20 21:18:31.000000,2009-01-21 08:40:51.000000,...,2009-01-25 00:23:00.000000,2009-01-01 01:49:06.000000,2009-01-25 14:48:00.000000,2009-01-22 20:53:00.000000,2009-01-25 13:20:00.000000],[2009-01-25 06:44:00.000000,2009-01-25 15:04:00.000000,2009-01-25 10:16:00.000000,2009-01-25 04:33:00.000000,2009-01-23 20:14:00.000000,...,2009-01-27 14:46:00.000000,2009-01-27 14:02:00.000000,2009-01-23 09:02:15.000000,2009-01-24 23:15:00.000000,2009-01-23 15:35:15.000000]]\n",
              "passenger_count: [[1,3,5,1,1,...,1,1,1,1,2],[2,2,2,1,2,...,2,2,1,1,1],...,[1,1,1,1,1,...,5,2,5,1,5],[5,1,1,5,1,...,5,1,1,3,1]]\n",
              "trip_distance: [[2.63,4.55,10.35,5,0.4,...,3.7,0.9,0.5,1.1,1.3],[1.1,0.6,0.9,1.2,1,...,1,6.8,1.3,0.7,1],...,[20.7,0.2,2.1,2.3,0.5,...,5.2,4.3,0.86,1.62,1.53],[1.43,0.58,1.36,3.02,2.91,...,0.89,1.94,3.8,3.85,17.3]]\n",
              "pickup_longitude: [[-73.99196,-73.9821,-74.00259,-73.974266,-74.00158,...,-73.992744,-73.99128,-73.98005,-73.97288,-73.9776],[-73.9908,-73.975716,-73.97441,-73.97065,-73.990135,...,-73.97786,-73.95457,0,-73.97422,-73.966644],...,[-73.78204,-73.98393,-73.979645,-73.99633,-73.98092,...,-73.97414,-73.982925,-73.953926,-73.999596,-73.99288],[-73.970604,-73.99453,-73.9917,-74.00047,-73.99772,...,-73.98201,-73.972786,-73.97747,-73.98129,0]]\n",
              "pickup_latitude: [[40.721565,40.73629,40.739746,40.790955,40.719383,...,40.713802,40.723892,40.754658,40.79333,40.752],[40.751076,40.748226,40.76322,40.752747,40.740852,...,40.74217,40.78086,0,40.783566,40.804012],...,[40.644768,40.749287,40.7554,40.737335,40.76395,...,40.78377,40.73503,40.76648,40.733482,40.72419],[40.76505,40.75172,40.739643,40.728706,40.72436,...,40.74333,40.76199,40.75186,40.753,0]]\n",
              "rate_code_id: [65536 nulls,65536 nulls,...,65536 nulls,2173 nulls]\n",
              "store_and_fwd_flag: [[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null],...,[null,null,null,null,null,...,null,null,null,null,null],[null,null,null,null,null,...,null,null,null,null,null]]\n",
              "dropoff_longitude: [[-73.993805,-73.95585,-73.86998,-73.99656,-74.00838,...,-73.98663,-73.98523,-73.98596,-73.981995,-73.99347],[-74.00014,-73.97249,-73.98696,-73.98271,-73.99506,...,-73.98757,-73.93975,0,-73.982,-73.95343],...,[-73.96209,-73.98791,-74.005585,-73.97921,-73.98632,...,-73.917816,-73.96772,-73.96618,-74.00464,-74.00712],[-73.980606,-74.00163,-73.97803,-73.97005,-73.98376,...,-73.99433,-73.95148,-74.00991,-73.949455,0]]\n",
              "..."
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "frag_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d626148d",
      "metadata": {
        "id": "d626148d"
      },
      "source": [
        "#### Chunks: The Building Blocks\n",
        "\n",
        "* Remember how we talked about Arrow tables having columns that could be split into chunks?\n",
        "* If you take a look, each column is divided into 216 chunks\n",
        "  * Proving that this table is built in the way we discussed earlier.\n",
        "* Take just a slice of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "b60f1dce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b60f1dce",
        "outputId": "6a97e515-95aa-4073-ed63-eb08d5962e9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "vendor_id: string\n",
              "pickup_at: timestamp[us]\n",
              "dropoff_at: timestamp[us]\n",
              "passenger_count: int8\n",
              "trip_distance: float\n",
              "pickup_longitude: float\n",
              "pickup_latitude: float\n",
              "rate_code_id: null\n",
              "store_and_fwd_flag: string\n",
              "dropoff_longitude: float\n",
              "dropoff_latitude: float\n",
              "payment_type: string\n",
              "fare_amount: float\n",
              "extra: float\n",
              "mta_tax: float\n",
              "tip_amount: float\n",
              "tolls_amount: float\n",
              "total_amount: float\n",
              "----\n",
              "vendor_id: [[\"VTS\",\"VTS\",\"VTS\",\"DDS\",\"DDS\"]]\n",
              "pickup_at: [[2009-01-04 02:52:00.000000,2009-01-04 03:31:00.000000,2009-01-03 15:43:00.000000,2009-01-01 20:52:58.000000,2009-01-24 16:18:23.000000]]\n",
              "dropoff_at: [[2009-01-04 03:02:00.000000,2009-01-04 03:38:00.000000,2009-01-03 15:57:00.000000,2009-01-01 21:14:00.000000,2009-01-24 16:24:56.000000]]\n",
              "passenger_count: [[1,3,5,1,1]]\n",
              "trip_distance: [[2.63,4.55,10.35,5,0.4]]\n",
              "pickup_longitude: [[-73.99196,-73.9821,-74.00259,-73.974266,-74.00158]]\n",
              "pickup_latitude: [[40.721565,40.73629,40.739746,40.790955,40.719383]]\n",
              "rate_code_id: [5 nulls]\n",
              "store_and_fwd_flag: [[null,null,null,null,null]]\n",
              "dropoff_longitude: [[-73.993805,-73.95585,-73.86998,-73.99656,-74.00838]]\n",
              "..."
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "frag_table.slice(0, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "423b3adc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "423b3adc",
        "outputId": "d6d16007-04df-4694-de10-8f84f522ebb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216,\n",
              " 216]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "[frag_table[col_name].num_chunks for col_name in frag_table.column_names]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa3e6dd",
      "metadata": {
        "id": "efa3e6dd"
      },
      "source": [
        "### The Essentials of Apache Arrow Tables and Record Batches\n",
        "\n",
        "*  Tables in Apache Arrow are essentially collections of record batches.\n",
        "*  You can easily pull data from columns like `payment_type`, `fare_amount`, or `tip_amount`.\n",
        "* Because we're working with a single record batch, managing the data is pretty straightforward.\n",
        "  * We'll see that each column, for instance, holds 65,536 values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "cf90cabf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf90cabf",
        "outputId": "f7f733a8-5702-4b04-836b-de86cab6b4bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyarrow.RecordBatch\n",
              "vendor_id: string\n",
              "pickup_at: timestamp[us]\n",
              "dropoff_at: timestamp[us]\n",
              "passenger_count: int8\n",
              "trip_distance: float\n",
              "pickup_longitude: float\n",
              "pickup_latitude: float\n",
              "rate_code_id: null\n",
              "store_and_fwd_flag: string\n",
              "dropoff_longitude: float\n",
              "dropoff_latitude: float\n",
              "payment_type: string\n",
              "fare_amount: float\n",
              "extra: float\n",
              "mta_tax: float\n",
              "tip_amount: float\n",
              "tolls_amount: float\n",
              "total_amount: float"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "record_batch_3 = frag_table.to_batches()[3]\n",
        "record_batch_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "30cbb487",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30cbb487",
        "outputId": "12898bbe-9237-406a-c209-895a22f957f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65536"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "record_batch_3.num_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "136d7fe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "136d7fe4",
        "outputId": "00a9bd77-00ef-4478-993b-12a7882d9bc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.FloatArray object at 0x7faa600fab60>\n",
              "[\n",
              "  4.9,\n",
              "  10.5,\n",
              "  4.2,\n",
              "  8.2,\n",
              "  3.8,\n",
              "  17.8,\n",
              "  9.8,\n",
              "  6.9,\n",
              "  3.7,\n",
              "  10.5,\n",
              "  ...\n",
              "  45,\n",
              "  6.9,\n",
              "  6.2,\n",
              "  25.3,\n",
              "  5.7,\n",
              "  25.3,\n",
              "  5.3,\n",
              "  24.1,\n",
              "  6.9,\n",
              "  22.1\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "record_batch_3[\"fare_amount\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "0735bc74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0735bc74",
        "outputId": "b217b5ca-6733-429c-a109-d3fc20bca7cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.FloatArray object at 0x7faa600fa920>\n",
              "[\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0.76,\n",
              "  2.67,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  ...\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  5.06,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "record_batch_3['tip_amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "8074fa20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8074fa20",
        "outputId": "0c723a1b-c6a4-43f2-bfd7-1351e4a7d25e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.StringArray object at 0x7faa600fa7a0>\n",
              "[\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"Cash\",\n",
              "  \"Cash\",\n",
              "  \"Credit\",\n",
              "  \"Credit\",\n",
              "  \"Credit\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"Cash\",\n",
              "  ...\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"Cash\",\n",
              "  \"Credit\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"Credit\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CASH\"\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "record_batch_3['payment_type']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca75535c",
      "metadata": {
        "id": "ca75535c"
      },
      "source": [
        "#### PyArrow's Computational Capabilities\n",
        "\n",
        "*   PyArrow separates data storage concerns from computational functionality.    \n",
        "    * Structures like Arrow Arrays, Record Batches, and Tables handle data storage and serialization.\n",
        "    * For actual data operations, there's the `pyarrow.compute` module.\n",
        "*   The `pyarrow.compute` module offers a range of functions for filtering, transforming, and aggregating data.    \n",
        "    * While it does provide useful operations, it's not a full-blown analytical tool.\n",
        "    * For more complex tasks, you'd typically use something like Pandas or Spark.\n",
        "\n",
        "* Let's perform some computations like calculating the sum of tips and fares, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "c46b7280",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46b7280",
        "outputId": "6a506147-3854-40a8-e28f-4d1f38fc250c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.FloatArray object at 0x7faa600fa980>\n",
              "[\n",
              "  4.9,\n",
              "  10.5,\n",
              "  4.2,\n",
              "  8.2,\n",
              "  4.56,\n",
              "  20.47,\n",
              "  11.8,\n",
              "  6.9,\n",
              "  3.7,\n",
              "  10.5,\n",
              "  ...\n",
              "  45,\n",
              "  6.9,\n",
              "  6.2,\n",
              "  30.359999,\n",
              "  5.7,\n",
              "  25.3,\n",
              "  6.3,\n",
              "  24.1,\n",
              "  6.9,\n",
              "  22.1\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "import pyarrow.compute as pc\n",
        "pc.add(record_batch_3['tip_amount'], record_batch_3['fare_amount'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0365b652",
      "metadata": {
        "id": "0365b652"
      },
      "source": [
        "* How about finding the maximum total amount for a trip, including the tip?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "272d4043",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "272d4043",
        "outputId": "f8d92e37-ce1f-4963-cddb-16eb0657849e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.FloatScalar: 164.0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "pc.max(pc.add(record_batch_3['tip_amount'], record_batch_3['fare_amount']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09e0bcf",
      "metadata": {
        "id": "d09e0bcf"
      },
      "source": [
        "* And the average?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "5162427e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5162427e",
        "outputId": "6be4f8fa-9a96-446b-fc9e-e81fd0ee5511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.DoubleScalar: 10.015554052642983>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "pc.mean(pc.add(record_batch_3['tip_amount'], record_batch_3['fare_amount']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824a8057",
      "metadata": {
        "id": "824a8057"
      },
      "source": [
        "* We can also perform operations on string data, like converting the case of `payment_type`, which has been recorded inconsistently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "c4ea7d0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ea7d0c",
        "outputId": "df593102-60f9-4e1d-b474-a24f06e09c01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.StringArray object at 0x7faa600fa680>\n",
              "[\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CREDIT\",\n",
              "  \"CREDIT\",\n",
              "  \"CREDIT\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  ...\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CREDIT\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CREDIT\",\n",
              "  \"CASH\",\n",
              "  \"CASH\",\n",
              "  \"CASH\"\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "upper_cased_payment_type = pc.utf8_upper(record_batch_3[\"payment_type\"])\n",
        "upper_cased_payment_type"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f3597a",
      "metadata": {
        "id": "92f3597a"
      },
      "source": [
        "* You can then filter data based on whether the payment type was \"CASH.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "6c334143",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c334143",
        "outputId": "67ad7fae-ff09-4c17-a3ae-3073cb318979"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.BooleanArray object at 0x7faa600b4700>\n",
              "[\n",
              "  true,\n",
              "  true,\n",
              "  true,\n",
              "  true,\n",
              "  false,\n",
              "  false,\n",
              "  false,\n",
              "  true,\n",
              "  true,\n",
              "  true,\n",
              "  ...\n",
              "  true,\n",
              "  true,\n",
              "  true,\n",
              "  false,\n",
              "  true,\n",
              "  true,\n",
              "  false,\n",
              "  true,\n",
              "  true,\n",
              "  true\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "is_cash = pc.equal(upper_cased_payment_type, pa.scalar('CASH'))\n",
        "is_cash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "9ff03b28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ff03b28",
        "outputId": "094e4493-2ecf-4055-e1c3-68e9f13d66cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51341"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "filtered_record_batch_3 = pc.filter(record_batch_3, is_cash)\n",
        "filtered_record_batch_3\n",
        "filtered_record_batch_3.num_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b7912d0",
      "metadata": {
        "id": "3b7912d0"
      },
      "source": [
        "\n",
        "#### Working with Parquet Files\n",
        "\n",
        "* You can read Parquet data into PyArrow as a ParquetDataset, and then work with it as ParquetFile Fragments.\n",
        "* Recall that:\n",
        "    * Each fragment has its own metadata,\n",
        "    * You can also get statistics about each row group within the fragment.\n",
        "      * However, it's usually more efficient to work with sorted data if you carry out frequent operations\n",
        "      * You can then save this sorted table into a new Parquet file for optimized data retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "0192afbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0192afbe",
        "outputId": "c68c661b-8691-4c60-8963-af8e0d19cec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9.0.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "import pyarrow\n",
        "pyarrow.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "bb1e6667",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb1e6667",
        "outputId": "3b22ca1d-6f8b-45d3-f818-c31793cfcae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here\n"
          ]
        }
      ],
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "dataset = pq.ParquetDataset('s3://ursa-labs-taxi-data/2009/', partitioning=[\"month\"], use_legacy_dataset=False)\n",
        "\n",
        "print(\"here\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "record_batch_3['pickup_at']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgs2m8ueXbp_",
        "outputId": "952d25e0-e05d-4efa-ab3c-249eefa03d27"
      },
      "id": "mgs2m8ueXbp_",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.TimestampArray object at 0x7faa58771f60>\n",
              "[\n",
              "  2009-01-12 12:54:37.000000,\n",
              "  2009-01-12 17:24:48.000000,\n",
              "  2009-01-10 23:45:52.000000,\n",
              "  2009-01-10 19:45:10.000000,\n",
              "  2009-01-10 23:41:18.000000,\n",
              "  2009-01-10 23:41:38.000000,\n",
              "  2009-01-31 20:03:56.000000,\n",
              "  2009-01-23 13:16:40.000000,\n",
              "  2009-01-13 00:09:28.000000,\n",
              "  2009-01-29 15:50:01.000000,\n",
              "  ...\n",
              "  2009-01-03 13:57:00.000000,\n",
              "  2009-01-03 22:47:00.000000,\n",
              "  2009-01-18 04:10:02.000000,\n",
              "  2009-01-03 18:28:00.000000,\n",
              "  2009-01-03 15:38:00.000000,\n",
              "  2009-01-03 16:19:00.000000,\n",
              "  2009-01-03 23:05:00.000000,\n",
              "  2009-01-25 07:50:00.000000,\n",
              "  2009-01-02 15:28:00.000000,\n",
              "  2009-01-04 07:08:00.000000\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "13072afb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13072afb",
        "outputId": "1693d660-cf92-4202-d4c0-62b79772d271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.7 s, sys: 4.44 s, total: 27.1 s\n",
            "Wall time: 24.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_table = dataset.fragments[0].to_table()\n",
        "sorted_indices = pc.sort_indices(data_table, sort_keys=[(\"pickup_at\", \"ascending\"), (\"fare_amount\", \"ascending\")])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "8c1269cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1269cc",
        "outputId": "1bef109c-7a65-44b9-e072-f2e45237d38a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyarrow.lib.UInt64Array object at 0x7fa986fdf8e0>\n",
              "[\n",
              "  11489987,\n",
              "  3964040,\n",
              "  543513,\n",
              "  8582999,\n",
              "  11812099,\n",
              "  3708729,\n",
              "  10177659,\n",
              "  12142978,\n",
              "  4811616,\n",
              "  5665566,\n",
              "  ...\n",
              "  10604876,\n",
              "  10079366,\n",
              "  1839956,\n",
              "  4631967,\n",
              "  8528489,\n",
              "  347071,\n",
              "  3174063,\n",
              "  6071930,\n",
              "  1328472,\n",
              "  7684378\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "sorted_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "c4af0862",
      "metadata": {
        "id": "c4af0862"
      },
      "outputs": [],
      "source": [
        "# takes the instances in the order specified in the variable sorted_indices\n",
        "# i.e., sorting the data\n",
        "sorted_table = data_table.take(sorted_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "344ee6e0",
      "metadata": {
        "id": "344ee6e0"
      },
      "outputs": [],
      "source": [
        "pq.write_table(sorted_table, 'optimized_parquet_file.parquet', row_group_size=65536)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e33953a7",
      "metadata": {
        "id": "e33953a7"
      },
      "source": [
        "\n",
        "#### Exploring Sorted Parquet Files\n",
        "\n",
        "*   When you read the sorted table back into PyArrow, it's easier to work with.\n",
        "  * We can reach the read groups meta data and only look at those we are interested in.\n",
        "  * i.e., you can delve into the metadata to understand your data better.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "836dc2e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "836dc2e2",
        "outputId": "160e4ef7-546b-4ec8-fa6a-27b452388ad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_columns': 18,\n",
              " 'num_rows': 65536,\n",
              " 'total_byte_size': 1645654,\n",
              " 'columns': [{'file_offset': 8548,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'BYTE_ARRAY',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'vendor_id',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': 'CMT',\n",
              "    'max': 'DDS',\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'BYTE_ARRAY'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 4,\n",
              "   'data_page_offset': 34,\n",
              "   'total_compressed_size': 8544,\n",
              "   'total_uncompressed_size': 9856},\n",
              "  {'file_offset': 196427,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'INT64',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'pickup_at',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': datetime.datetime(2009, 1, 1, 0, 0),\n",
              "    'max': datetime.datetime(2009, 1, 1, 4, 22, 17),\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'INT64'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 8622,\n",
              "   'data_page_offset': 101500,\n",
              "   'total_compressed_size': 187805,\n",
              "   'total_uncompressed_size': 234517},\n",
              "  {'file_offset': 406433,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'INT64',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'dropoff_at',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': datetime.datetime(2009, 1, 1, 0, 1, 13),\n",
              "    'max': datetime.datetime(2009, 1, 1, 15, 40, 42),\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'INT64'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 196535,\n",
              "   'data_page_offset': 291529,\n",
              "   'total_compressed_size': 209898,\n",
              "   'total_uncompressed_size': 242979},\n",
              "  {'file_offset': 431291,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'INT32',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'passenger_count',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': 0,\n",
              "    'max': 5,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'INT32'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 406542,\n",
              "   'data_page_offset': 406582,\n",
              "   'total_compressed_size': 24749,\n",
              "   'total_uncompressed_size': 24741},\n",
              "  {'file_offset': 506407,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'trip_distance',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -0.0,\n",
              "    'max': 47.0,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 431389,\n",
              "   'data_page_offset': 432479,\n",
              "   'total_compressed_size': 75018,\n",
              "   'total_uncompressed_size': 75004},\n",
              "  {'file_offset': 667665,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'pickup_longitude',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -74.77455139160156,\n",
              "    'max': 0.0,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 506503,\n",
              "   'data_page_offset': 552777,\n",
              "   'total_compressed_size': 161162,\n",
              "   'total_uncompressed_size': 161147},\n",
              "  {'file_offset': 890795,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'pickup_latitude',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -0.0,\n",
              "    'max': 45.0639533996582,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 667764,\n",
              "   'data_page_offset': 767715,\n",
              "   'total_compressed_size': 223031,\n",
              "   'total_uncompressed_size': 223011},\n",
              "  {'file_offset': 890940,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'INT32',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'rate_code_id',\n",
              "   'is_stats_set': False,\n",
              "   'statistics': None,\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 890893,\n",
              "   'data_page_offset': 890908,\n",
              "   'total_compressed_size': 47,\n",
              "   'total_uncompressed_size': 44},\n",
              "  {'file_offset': 891054,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'BYTE_ARRAY',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'store_and_fwd_flag',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': False,\n",
              "    'min': None,\n",
              "    'max': None,\n",
              "    'null_count': 65536,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 0,\n",
              "    'physical_type': 'BYTE_ARRAY'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 891003,\n",
              "   'data_page_offset': 891018,\n",
              "   'total_compressed_size': 51,\n",
              "   'total_uncompressed_size': 48},\n",
              "  {'file_offset': 1063819,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'dropoff_longitude',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -74.77429962158203,\n",
              "    'max': 0.0,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 891129,\n",
              "   'data_page_offset': 948931,\n",
              "   'total_compressed_size': 172690,\n",
              "   'total_uncompressed_size': 172675},\n",
              "  {'file_offset': 1299061,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'dropoff_latitude',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -0.0,\n",
              "    'max': 45.06427764892578,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1063920,\n",
              "   'data_page_offset': 1175981,\n",
              "   'total_compressed_size': 235141,\n",
              "   'total_uncompressed_size': 235123},\n",
              "  {'file_offset': 1320093,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'BYTE_ARRAY',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'payment_type',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': 'CASH',\n",
              "    'max': 'No Charge',\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'BYTE_ARRAY'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1299163,\n",
              "   'data_page_offset': 1299234,\n",
              "   'total_compressed_size': 20930,\n",
              "   'total_uncompressed_size': 23899},\n",
              "  {'file_offset': 1395542,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'fare_amount',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': 2.5,\n",
              "    'max': 200.0,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1320184,\n",
              "   'data_page_offset': 1321614,\n",
              "   'total_compressed_size': 75358,\n",
              "   'total_uncompressed_size': 75344},\n",
              "  {'file_offset': 1404159,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'extra',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -0.0,\n",
              "    'max': 0.5,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1395639,\n",
              "   'data_page_offset': 1395663,\n",
              "   'total_compressed_size': 8520,\n",
              "   'total_uncompressed_size': 9871},\n",
              "  {'file_offset': 1404301,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'mta_tax',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': False,\n",
              "    'min': None,\n",
              "    'max': None,\n",
              "    'null_count': 65536,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 0,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1404250,\n",
              "   'data_page_offset': 1404265,\n",
              "   'total_compressed_size': 51,\n",
              "   'total_uncompressed_size': 48},\n",
              "  {'file_offset': 1437542,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'tip_amount',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -0.0,\n",
              "    'max': 95.44999694824219,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1404368,\n",
              "   'data_page_offset': 1406184,\n",
              "   'total_compressed_size': 33174,\n",
              "   'total_uncompressed_size': 56230},\n",
              "  {'file_offset': 1440678,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'tolls_amount',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': -0.0,\n",
              "    'max': 20.0,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1437638,\n",
              "   'data_page_offset': 1437816,\n",
              "   'total_compressed_size': 3040,\n",
              "   'total_uncompressed_size': 6593},\n",
              "  {'file_offset': 1535316,\n",
              "   'file_path': '',\n",
              "   'physical_type': 'FLOAT',\n",
              "   'num_values': 65536,\n",
              "   'path_in_schema': 'total_amount',\n",
              "   'is_stats_set': True,\n",
              "   'statistics': {'has_min_max': True,\n",
              "    'min': 2.5,\n",
              "    'max': 200.0,\n",
              "    'null_count': 0,\n",
              "    'distinct_count': 0,\n",
              "    'num_values': 65536,\n",
              "    'physical_type': 'FLOAT'},\n",
              "   'compression': 'SNAPPY',\n",
              "   'encodings': ('RLE_DICTIONARY', 'PLAIN', 'RLE'),\n",
              "   'has_dictionary_page': True,\n",
              "   'dictionary_page_offset': 1440774,\n",
              "   'data_page_offset': 1445004,\n",
              "   'total_compressed_size': 94542,\n",
              "   'total_uncompressed_size': 94524}]}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "optimized_parquet_file = pq.ParquetFile('optimized_parquet_file.parquet')\n",
        "\n",
        "rg0_metadata = optimized_parquet_file.metadata.row_group(0)\n",
        "rg0_metadata.to_dict()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "c3fd4dd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3fd4dd8",
        "outputId": "0c0ad1c1-9992-47dc-dcdf-8cd6aabf69d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'vendor_id'),\n",
              " (1, 'pickup_at'),\n",
              " (2, 'dropoff_at'),\n",
              " (3, 'passenger_count'),\n",
              " (4, 'trip_distance'),\n",
              " (5, 'pickup_longitude'),\n",
              " (6, 'pickup_latitude'),\n",
              " (7, 'rate_code_id'),\n",
              " (8, 'store_and_fwd_flag'),\n",
              " (9, 'dropoff_longitude'),\n",
              " (10, 'dropoff_latitude'),\n",
              " (11, 'payment_type'),\n",
              " (12, 'fare_amount'),\n",
              " (13, 'extra'),\n",
              " (14, 'mta_tax'),\n",
              " (15, 'tip_amount'),\n",
              " (16, 'tolls_amount'),\n",
              " (17, 'total_amount')]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "[(i,x[\"path_in_schema\"]) for i, x in enumerate(rg0_metadata.to_dict()[\"columns\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "9f7785bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f7785bf",
        "outputId": "2688a9da-7a78-4e1e-bbbb-5011f1dad109"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vendor_id': 0,\n",
              " 'pickup_at': 1,\n",
              " 'dropoff_at': 2,\n",
              " 'passenger_count': 3,\n",
              " 'trip_distance': 4,\n",
              " 'pickup_longitude': 5,\n",
              " 'pickup_latitude': 6,\n",
              " 'rate_code_id': 7,\n",
              " 'store_and_fwd_flag': 8,\n",
              " 'dropoff_longitude': 9,\n",
              " 'dropoff_latitude': 10,\n",
              " 'payment_type': 11,\n",
              " 'fare_amount': 12,\n",
              " 'extra': 13,\n",
              " 'mta_tax': 14,\n",
              " 'tip_amount': 15,\n",
              " 'tolls_amount': 16,\n",
              " 'total_amount': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "name_2_pos = {x[\"path_in_schema\"]:i for i, x in enumerate(rg0_metadata.to_dict()[\"columns\"])}\n",
        "name_2_pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "a464a355",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a464a355",
        "outputId": "aa240c6f-ea05-45ba-fc77-80a51a32a492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found it, it's row_group 2\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "col_idx = name_2_pos['pickup_at']\n",
        "\n",
        "datetime_obj = datetime.strptime(\"2009-1-1 14:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "for i in range(optimized_parquet_file.num_row_groups):\n",
        "    col_stats = optimized_parquet_file.metadata.row_group(i).column(col_idx).statistics\n",
        "    if col_stats.min <= datetime_obj <= col_stats.max:\n",
        "        print(f\"found it, it's row_group {i}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487f1bec",
      "metadata": {
        "id": "487f1bec"
      },
      "outputs": [],
      "source": [
        "### Bonus Questions\n",
        "* can you get the average transaction between 2:00-2:59 PM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "start_datetime_obj = datetime.strptime(\"2009-1-1 14:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
        "end_datetime_obj = start_datetime_obj + timedelta(minutes=59)\n",
        "\n",
        "sum_total = 0.0\n",
        "count = 0\n",
        "\n",
        "for i in range(optimized_parquet_file.num_row_groups):\n",
        "    col_stats = optimized_parquet_file.metadata.row_group(i).column(col_idx).statistics\n",
        "    if col_stats.min <= end_datetime_obj and col_stats.max >= start_datetime_obj:\n",
        "        data = optimized_parquet_file.read_row_group(i, columns=['pickup_at', 'total_amount'])\n",
        "\n",
        "        pickup_at_list = data.column('pickup_at').to_pylist()\n",
        "        total_amount_list = data.column('total_amount').to_pylist()\n",
        "\n",
        "        for j, pickup_at in enumerate(pickup_at_list):\n",
        "              sum_total += total_amount_list[j]\n",
        "              count += 1\n",
        "\n",
        "average_transaction = sum_total / count\n",
        "\n",
        "print(\"Average Transaction: \", average_transaction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFSi_X90p14u",
        "outputId": "dd9089ec-3c6b-473a-e400-75e78e2300c9"
      },
      "id": "OFSi_X90p14u",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Transaction:  10.257947722740937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef62566",
      "metadata": {
        "id": "1ef62566"
      },
      "outputs": [],
      "source": [
        "* Which day, on average has the highest tip?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_tips = [0] * 7\n",
        "\n",
        "for i in range(optimized_parquet_file.num_row_groups):\n",
        "    data = optimized_parquet_file.read_row_group(i, columns=['pickup_at', 'tip_amount'])\n",
        "\n",
        "    for j in range(data.num_rows):\n",
        "        tip = data.column('tip_amount')[j].as_py()\n",
        "        day = data.column('pickup_at')[j].as_py().weekday()\n",
        "        sum_tips[day] += tip\n",
        "\n",
        "max_tip_at_day = sum_tips.index(max(sum_tips))\n",
        "print(f\"Highest total tip at day: {max_tip_at_day}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOKTufuYfAr9",
        "outputId": "69778dc2-206a-42cd-e5c2-51adb6b27013"
      },
      "id": "yOKTufuYfAr9",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest total tip at day: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a203d1",
      "metadata": {
        "id": "44a203d1"
      },
      "outputs": [],
      "source": [
        "* Which time (hour) of the day has the highest tip?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "8d501b30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d501b30",
        "outputId": "426ad304-9481-409e-e393-d8af59948b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hour with the highest total tip is: 19\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sum_tips = [0] * 24\n",
        "\n",
        "for i in range(optimized_parquet_file.num_row_groups):\n",
        "    data = optimized_parquet_file.read_row_group(i, columns=['pickup_at', 'tip_amount'])\n",
        "\n",
        "    for j in range(data.num_rows):\n",
        "        tip = data.column('tip_amount')[j].as_py()\n",
        "        pickup_hour = data.column('pickup_at')[j].as_py().hour\n",
        "        sum_tips[pickup_hour] += tip\n",
        "\n",
        "\n",
        "hour_max_tips = sum_tips.index(max(sum_tips))\n",
        "print(f\"The hour with the highest total tip is: {hour_max_tips}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d45c6c",
      "metadata": {
        "id": "d4d45c6c"
      },
      "source": [
        "### Resources\n",
        "\n",
        "1.  [Apache Arrow Homepage](https://arrow.apache.org/)\n",
        "2.  [PyArrow Documentation](https://arrow.apache.org/docs/python/)\n",
        "3.  [PyArrow GitHub Repository](https://github.com/apache/arrow/tree/master/python/pyarrow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7262ab3f",
      "metadata": {
        "id": "7262ab3f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}